version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: traffy_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: traffy_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - traffy_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Apache Airflow (Standalone)
  airflow:
    image: apache/airflow:2.8.0-python3.10
    container_name: traffy_airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/traffy_db
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__SECRET_KEY=supersecretkey123
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./ml_models:/opt/airflow/ml_models
      - ./web_scraping:/opt/airflow/web_scraping
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - traffy_network
    command: >
      bash -c "airflow db init &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
               airflow webserver & airflow scheduler"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MongoDB (for external data storage)
  mongodb:
    image: mongo:7.0
    container_name: traffy_mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - traffy_network

  # Redis (for caching)
  redis:
    image: redis:7-alpine
    container_name: traffy_redis
    ports:
      - "6379:6379"
    networks:
      - traffy_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Streamlit Dashboard
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    container_name: traffy_dashboard
    ports:
      - "8501:8501"
    volumes:
      - ./visualization:/app/visualization
      - ./data:/app/data
      - ./ml_models:/app/ml_models
    environment:
      - PYTHONUNBUFFERED=1
    networks:
      - traffy_network
    command: streamlit run visualization/dashboard/app.py --server.port 8501 --server.address 0.0.0.0

  # Jupyter Notebook (for development)
  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: traffy_jupyter
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./ml_models:/home/jovyan/ml_models
    environment:
      - JUPYTER_ENABLE_LAB=yes
    networks:
      - traffy_network
    command: start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''

  # Apache Spark Master
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: traffy_spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8082:8080"  # Spark UI
      - "7077:7077"  # Spark Master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./data_engineering/spark:/opt/bitnami/spark/jobs
    networks:
      - traffy_network

  # Apache Spark Worker
  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: traffy_spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./data_engineering/spark:/opt/bitnami/spark/jobs
    networks:
      - traffy_network

volumes:
  postgres_data:
  mongodb_data:

networks:
  traffy_network:
    driver: bridge
